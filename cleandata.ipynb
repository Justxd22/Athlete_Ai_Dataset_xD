{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effective_time_frame</th>\n",
       "      <th>injuries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-07T06:39:48.428Z</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-11T13:47:05.617Z</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-18T08:28:53.208Z</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-25T08:10:11.478Z</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-02T08:10:19.841Z</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       effective_time_frame injuries\n",
       "0  2019-11-07T06:39:48.428Z       {}\n",
       "1  2019-11-11T13:47:05.617Z       {}\n",
       "2  2019-11-18T08:28:53.208Z       {}\n",
       "3  2019-11-25T08:10:11.478Z       {}\n",
       "4  2019-12-02T08:10:19.841Z       {}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "x = pd.read_csv('pmdata/p01/pmsys/injury.csv')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date    value\n",
      "0   2019-11-01  14424.0\n",
      "1   2019-11-02  10585.0\n",
      "2   2019-11-03  11461.0\n",
      "3   2019-11-04   8860.0\n",
      "4   2019-11-05  13715.0\n",
      "5   2019-11-06   6522.0\n",
      "6   2019-11-07   7048.0\n",
      "7   2019-11-08  10369.0\n",
      "8   2019-11-09  13287.0\n",
      "9   2019-11-10  14367.0\n",
      "10  2019-11-11  10825.0\n",
      "11  2019-11-12   8392.0\n",
      "12  2019-11-13   9021.0\n",
      "13  2019-11-14  15472.0\n",
      "14  2019-11-15  15022.0\n",
      "15  2019-11-16  12360.0\n",
      "16  2019-11-17   9602.0\n",
      "17  2019-11-18   7068.0\n",
      "18  2019-11-19   5718.0\n",
      "19  2019-11-20   8112.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON file\n",
    "with open('/home/xd/Documents/code/athledai/pmdata/p01/fitbit/distance.json', 'r') as file:\n",
    "    f = json.load(file)\n",
    "\n",
    "# Ensure data is a list\n",
    "if not isinstance(f, list):\n",
    "    raise ValueError(\"Expected a list of dictionaries in JSON file.\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(f)\n",
    "\n",
    "# Convert dateTime to pandas datetime format\n",
    "df['dateTime'] = pd.to_datetime(df['dateTime'])\n",
    "\n",
    "# Convert value column to integer (handling possible string format)\n",
    "df['value'] = pd.to_numeric(df['value'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Extract only the date (removing time part)\n",
    "df['date'] = df['dateTime'].dt.date\n",
    "\n",
    "# Group by date and sum values\n",
    "result = df.groupby('date', as_index=False)['value'].sum()\n",
    "result['value'] = round(result['value'] / 100)\n",
    "\n",
    "# Display the first few rows\n",
    "print(result.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id        date  sleep  sleep_quality\n",
      "2008     p16  2019-11-01   6.38             91\n",
      "1275     p09  2019-11-01   4.85             93\n",
      "360      p03  2019-11-01   2.10             93\n",
      "359      p03  2019-11-02   6.13             89\n",
      "688      p05  2019-11-02   5.05             96\n",
      "2009     p16  2019-11-02   6.62             94\n",
      "828      p06  2019-11-02   8.05             98\n",
      "140      p01  2019-11-02   6.30             97\n",
      "2010     p16  2019-11-03   5.70             92\n",
      "138      p01  2019-11-03   6.30             96\n",
      "618      p05  2019-11-03   3.73             89\n",
      "1276     p09  2019-11-03   6.22             96\n",
      "829      p06  2019-11-03   5.42             95\n",
      "830      p06  2019-11-04   6.52             97\n",
      "118      p01  2019-11-04   6.02             96\n",
      "1277     p09  2019-11-04   5.07             96\n",
      "2011     p16  2019-11-04   8.83             89\n",
      "2012     p16  2019-11-05   8.20             92\n",
      "831      p06  2019-11-05   6.57             98\n",
      "132      p01  2019-11-05   5.43             99\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sleep</th>\n",
       "      <th>sleep_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1881.000000</td>\n",
       "      <td>1881.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.628017</td>\n",
       "      <td>94.470494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.670824</td>\n",
       "      <td>4.033544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.930000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.750000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.600000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.720000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sleep  sleep_quality\n",
       "count  1881.000000    1881.000000\n",
       "mean      6.628017      94.470494\n",
       "std       1.670824       4.033544\n",
       "min       0.650000       0.000000\n",
       "25%       5.930000      93.000000\n",
       "50%       6.750000      95.000000\n",
       "75%       7.600000      97.000000\n",
       "max      13.720000     100.000000"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "main_folder_path = \"./pmdata\"\n",
    "sleep = []\n",
    "\n",
    "# Iterate through the 16 main folders\n",
    "for folder_name in os.listdir(main_folder_path):\n",
    "    folder_path = os.path.join(main_folder_path, folder_name, 'fitbit')\n",
    "\n",
    "    # Check if the subfolder exists\n",
    "    if os.path.exists(folder_path):\n",
    "        file_path = os.path.join(folder_path, 'sleep.json')\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as json_file:\n",
    "                # Load JSON data from the file\n",
    "                json_data = json.load(json_file)\n",
    "                # Add the data to the dictionary with the folder number as the key\n",
    "                df = pd.DataFrame(json_data)\n",
    "                df['user_id']= folder_name\n",
    "                sleep.append(df)\n",
    "\n",
    "# Combine all data\n",
    "result = pd.concat(sleep, ignore_index=True).sort_values(by=['user_id']).reset_index(drop=True)\n",
    "\n",
    "# Convert dateTime to pandas datetime format\n",
    "result['date'] = pd.to_datetime(result['dateOfSleep']).dt.date\n",
    "\n",
    "# Convert value column to integer (handling possible string format)\n",
    "result['sleep'] = round(pd.to_numeric(result['minutesAsleep'], errors='coerce').astype(int)/60, 2)\n",
    "\n",
    "# Extract only the date (removing time part)\n",
    "result['sleep_quality'] = pd.to_numeric(result['efficiency'], errors='coerce').astype(int)\n",
    "result = result[['user_id', 'date', 'sleep', 'sleep_quality']].sort_values(by=['date'])\n",
    "\n",
    "result = result.drop_duplicates(subset=['date', 'user_id'], keep='last')\n",
    "result.dropna()\n",
    "\n",
    "# Display the first few rows\n",
    "print(result.head(20))\n",
    "result.to_csv(\"sleep.csv\", index=False)\n",
    "\n",
    "# result.info()\n",
    "sleep = result\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>bpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-11-14</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-11-16</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-11-17</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  bpm\n",
       "0   2019-11-01  140\n",
       "1   2019-11-02  122\n",
       "2   2019-11-03  132\n",
       "3   2019-11-04  126\n",
       "4   2019-11-05  163\n",
       "5   2019-11-06  125\n",
       "6   2019-11-07  143\n",
       "7   2019-11-08  129\n",
       "8   2019-11-09  117\n",
       "9   2019-11-10  140\n",
       "10  2019-11-11  167\n",
       "11  2019-11-12  134\n",
       "12  2019-11-13  119\n",
       "13  2019-11-14  161\n",
       "14  2019-11-15  141\n",
       "15  2019-11-16  163\n",
       "16  2019-11-17  131\n",
       "17  2019-11-18  171\n",
       "18  2019-11-19  129\n",
       "19  2019-11-20  128"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON file\n",
    "with open('/home/xd/Documents/code/athledai/pmdata/p01/fitbit/heart_rate.json', 'r') as file:\n",
    "    f = json.load(file)\n",
    "\n",
    "# Ensure data is a list\n",
    "if not isinstance(f, list):\n",
    "    raise ValueError(\"Expected a list of dictionaries in JSON file.\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(f)\n",
    "result = pd.DataFrame()\n",
    "\n",
    "# Convert dateTime to pandas datetime format\n",
    "df['dateTime'] = pd.to_datetime(df['dateTime'])\n",
    "df['bpm'] = df['value'].apply(lambda x: x['bpm'])\n",
    "df['bpm'] = pd.to_numeric(df['bpm'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "df['date'] = df['dateTime'].dt.date\n",
    "\n",
    "result = df.groupby('date', as_index=False)['bpm'].max()\n",
    "result = result.drop_duplicates(subset=['date'], keep='first')\n",
    "result = result.dropna()\n",
    "\n",
    "# Display the first few rows\n",
    "result.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      weight alcohol_consumed user_id        date\n",
      "0        100               No     p01  2020-03-19\n",
      "1        100               No     p01  2019-12-23\n",
      "3        100               No     p01  2019-11-23\n",
      "4        100               No     p01  2019-11-24\n",
      "5        100               No     p01  2019-11-25\n",
      "...      ...              ...     ...         ...\n",
      "1563      64               No     p16  2019-12-08\n",
      "1565      64               No     p16  2019-12-10\n",
      "1566      64              Yes     p16  2019-12-11\n",
      "1567      64               No     p16  2019-11-28\n",
      "1568      64               No     p16  2020-03-18\n",
      "\n",
      "[1181 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79.784928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.598856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            weight\n",
       "count  1181.000000\n",
       "mean     79.784928\n",
       "std      14.598856\n",
       "min      58.000000\n",
       "25%      67.000000\n",
       "50%      73.000000\n",
       "75%      94.000000\n",
       "max     100.000000"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "main_folder_path = \"./pmdata\"\n",
    "alcohol = []\n",
    "\n",
    "# Iterate through the 16 main folders\n",
    "for folder_name in os.listdir(main_folder_path):\n",
    "    folder_path = os.path.join(main_folder_path, folder_name, 'googledocs')\n",
    "\n",
    "    # Check if the subfolder exists\n",
    "    if os.path.exists(folder_path):\n",
    "        file_path = os.path.join(folder_path, 'reporting.csv')\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['user_id'] = folder_name\n",
    "            alcohol.append(df)\n",
    "\n",
    "# print(alcohol[6])\n",
    "# Combine all data\n",
    "x = pd.concat(alcohol, ignore_index=True).sort_values(by=['user_id']).reset_index(drop=True)\n",
    "x = x.drop(columns=['date'])\n",
    "x['date'] = pd.to_datetime(x['timestamp'], dayfirst=True).dt.date\n",
    "x = x.drop(columns=['timestamp'])\n",
    "x = x.drop_duplicates(subset=['user_id', 'date'], keep='last')\n",
    "\n",
    "x = x[x['alcohol_consumed'] != \"Maybe\"]\n",
    "x = x[x['alcohol_consumed'] != \"Do not want to provide this information\"]\n",
    "x.value_counts('alcohol_consumed')\n",
    "\n",
    "# # Convert timestamp to date and drop duplicates\n",
    "# x['date'] = pd.to_datetime(x['timestamp'], format='%d/%m/%Y %H:%M:%S').dt.date\n",
    "x = x.drop(columns=['meals', 'glasses_of_fluid'])\n",
    "\n",
    "# # Fill missing weight values with the mean weight for each user_id\n",
    "x['weight'] = x.groupby('user_id')['weight'].transform(lambda grp: int(grp.mean()))\n",
    "\n",
    "# # Display results\n",
    "x.dropna()\n",
    "# x.info()\n",
    "# x.head()\n",
    "x.value_counts('alcohol_consumed')\n",
    "alcohol = x\n",
    "x.to_csv(\"alcholc.csv\", index=False)\n",
    "\n",
    "print(x)\n",
    "x.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  Age  Height  Gender MaxHR\n",
      "0      p01   48     195    male   182\n",
      "1      p02   60     180    male   169\n",
      "2      p03   25     184    male   157\n",
      "3      p04   26     163  female   195\n",
      "4      p05   35     176    male   184\n",
      "5      p06   42     179    male   181\n",
      "6      p07   26     177    male   180\n",
      "7      p08   27     186    male   200\n",
      "8      p09   26     180    male   183\n",
      "9      p10   38     179  female   197\n",
      "10     p11   25     171  female   203\n",
      "11     p12   27     178    male   180\n",
      "12     p13   31     183    male   186\n",
      "13     p14   45     181    male   190\n",
      "14     p15   54     180    male   160\n",
      "15     p16   23     182    male   199\n"
     ]
    }
   ],
   "source": [
    "user_data = pd.read_excel(r'/home/xd/Documents/code/athledai/pmdata/participant-overview.xlsx', parse_dates=['Date'], header=1)\n",
    "user_data.head()\n",
    "user_data.describe()\n",
    "user_data.rename(columns={'Participant ID': 'user_id'}, inplace=True)\n",
    "user_data.rename(columns={'Max heart rate': 'MaxHR'}, inplace=True)\n",
    "user_data = user_data.drop(columns=['A or B person', 'Date', 'Minutes', 'Seconds', 'Stride walk', 'Stride run'])\n",
    "# fill missing max HR from AvgHR Data\n",
    "user_data.loc[user_data['user_id'] == 'p12', 'MaxHR'] = 180\n",
    "user_data.loc[user_data['user_id'] == 'p15', 'MaxHR'] = 160\n",
    "user_data.loc[user_data['user_id'] == 'p07', 'MaxHR'] = 180\n",
    "user_data['Gender'] = user_data['Gender'].str.strip()\n",
    "\n",
    "\n",
    "print(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   avgHR             298 non-null    float64       \n",
      " 1   calories          299 non-null    int64         \n",
      " 2   duration          299 non-null    float64       \n",
      " 3   steps             299 non-null    float64       \n",
      " 4   startTime         299 non-null    datetime64[ns]\n",
      " 5   distance          299 non-null    float64       \n",
      " 6   speed             299 non-null    float64       \n",
      " 7   pace              299 non-null    float64       \n",
      " 8   user_id           299 non-null    object        \n",
      " 9   vo2Max            299 non-null    float64       \n",
      " 10  date              299 non-null    object        \n",
      " 11  Age               299 non-null    int64         \n",
      " 12  Height            299 non-null    int64         \n",
      " 13  Gender            299 non-null    object        \n",
      " 14  MaxHR             299 non-null    object        \n",
      " 15  weight            299 non-null    int64         \n",
      " 16  alcohol_consumed  299 non-null    object        \n",
      " 17  sleep             299 non-null    float64       \n",
      " 18  sleep_quality     299 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(9), int64(4), object(5)\n",
      "memory usage: 44.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "main_folder_path = \"./pmdata\"\n",
    "# Initialize an empty dictionary to store data for each column\n",
    "exercise = []\n",
    "# Iterate through the 16 main folders\n",
    "for folder_name in os.listdir(main_folder_path):\n",
    "    folder_path = os.path.join(main_folder_path, folder_name, 'fitbit')\n",
    "\n",
    "\n",
    "    # Check if the subfolder exists\n",
    "    if os.path.exists(folder_path):\n",
    "        file_path = os.path.join(folder_path, 'exercise.json')\n",
    "        \n",
    "        # Check if the \"exercise.json\" file exists in the subfolder\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as json_file:\n",
    "                # Load JSON data from the file\n",
    "                json_data = json.load(json_file)\n",
    "                # Add the data to the dictionary with the folder number as the key\n",
    "                df = pd.DataFrame(json_data)\n",
    "                df['user_id']= folder_name\n",
    "                exercise.append(df)\n",
    "\n",
    "exercise_data = pd.concat(exercise, ignore_index=True).sort_values(by=['user_id']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#Exploring the columns from the dataset.\n",
    "exercise_data = exercise_data.query(\"activityName == 'Run'\").dropna(subset=['distanceUnit'])\n",
    "exercise_data = exercise_data.drop(columns=['poolLengthUnit', 'hasGps', 'poolLength', 'swimLengths', 'logId', 'activityTypeId', 'logType', 'lastModified', 'tcxLink','distanceUnit', 'customHeartRateZones', 'shouldFetchDetails', 'manualValuesSpecified', 'source', 'activityLevel', 'heartRateZones', 'elevationGain', 'originalDuration', 'activeDuration', 'originalStartTime', 'activityName'])\n",
    "exercise_data = exercise_data[exercise_data[\"distance\"] > 0.5].reset_index(drop=True)\n",
    "exercise_data[\"vo2Max\"] = exercise_data[\"vo2Max\"].apply(lambda x: round(x.get(\"vo2Max\"), 2) if isinstance(x, dict) else None)\n",
    "exercise_data.loc[exercise_data['vo2Max'].isna(), 'vo2Max'] = pd.Series(\n",
    "    np.random.choice(\n",
    "        exercise_data['vo2Max'].dropna(),  # Sample from non-NaN values\n",
    "        size=exercise_data['vo2Max'].isna().sum(), \n",
    "        replace=True\n",
    "    ),\n",
    "    index=exercise_data[exercise_data['vo2Max'].isna()].index  # Maintain correct indices\n",
    ")\n",
    "exercise_data['startTime'] = pd.to_datetime(exercise_data['startTime'])\n",
    "exercise_data['duration'] = exercise_data['duration'] / 60000\n",
    "exercise_data['date'] = pd.to_datetime(exercise_data['startTime']).dt.date\n",
    "exercise_data.rename(columns={'averageHeartRate': 'avgHR'}, inplace=True)\n",
    "\n",
    "\n",
    "merged_df = exercise_data.merge(user_data, on='user_id', how='left')\n",
    "merged_df = merged_df.merge(x, on=['user_id', 'date'], how='left')\n",
    "merged_df = merged_df.drop_duplicates(keep='last')\n",
    "merged_df = merged_df.merge(sleep, on=['user_id', 'date'], how='left')\n",
    "\n",
    "\n",
    "# Fill missing 'alcohol_consumed' values with 'No'\n",
    "merged_df['alcohol_consumed'] = merged_df['alcohol_consumed'].fillna(\"No\")\n",
    "\n",
    "# Fill missing 'weight' values with the mean weight per user_id\n",
    "merged_df['weight'] = merged_df.groupby('user_id')['weight'].transform(lambda grp: round(grp.mean(skipna=True)) if grp.notna().any() else 80)\n",
    "merged_df['sleep'] = merged_df['sleep'].fillna(merged_df.groupby('user_id')['sleep'].transform(lambda grp: round(grp.mean(skipna=True)) if grp.notna().any() else 7))\n",
    "merged_df['sleep_quality'] = merged_df['sleep_quality'].fillna(merged_df.groupby('user_id')['sleep_quality'].transform(lambda grp: round(grp.mean(skipna=True)) if grp.notna().any() else 95))\n",
    "\n",
    "merged_df.dropna()\n",
    "\n",
    "\n",
    "merged_df.info()\n",
    "merged_df.describe()\n",
    "merged_df.to_csv(\"merged_data1.csv\", index=False)\n",
    "# merged_df.query(\"sleep_quality == 0\")\n",
    "\n",
    "\n",
    "# merged_df.head(10)\n",
    "# print(merged_df)\n",
    "\n",
    "# merged_df.describe()\n",
    "# exercise_data.head(10)\n",
    "# exercise_data.value_counts('avgHR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 270 entries, 0 to 269\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   avgHR             270 non-null    float64\n",
      " 1   calories          270 non-null    int64  \n",
      " 2   duration          270 non-null    float64\n",
      " 3   steps             270 non-null    float64\n",
      " 4   distance          270 non-null    float64\n",
      " 5   speed             270 non-null    float64\n",
      " 6   pace              270 non-null    float64\n",
      " 7   user_id           270 non-null    object \n",
      " 8   vo2Max            270 non-null    float64\n",
      " 9   date              270 non-null    object \n",
      " 10  Age               270 non-null    int64  \n",
      " 11  Height            270 non-null    int64  \n",
      " 12  Gender            270 non-null    object \n",
      " 13  MaxHR             270 non-null    object \n",
      " 14  weight            270 non-null    int64  \n",
      " 15  alcohol_consumed  270 non-null    object \n",
      " 16  sleep             270 non-null    float64\n",
      " 17  sleep_quality     270 non-null    float64\n",
      "dtypes: float64(9), int64(4), object(5)\n",
      "memory usage: 38.1+ KB\n",
      "None\n",
      "            avgHR     calories    duration         steps    distance  \\\n",
      "count  270.000000   270.000000  270.000000    270.000000  270.000000   \n",
      "mean   137.081481   652.433333   68.364481   7158.440741    6.984111   \n",
      "std     18.084088   445.899018   73.546064   4117.464824    4.206096   \n",
      "min     72.000000    31.000000    4.050000    595.000000    0.570000   \n",
      "25%    126.250000   306.250000   32.835000   4375.000000    4.170000   \n",
      "50%    141.000000   552.000000   49.840000   6461.500000    6.260000   \n",
      "75%    148.000000   916.250000   84.560000   9982.500000    9.557500   \n",
      "max    180.000000  2340.000000  865.020000  24119.000000   25.490000   \n",
      "\n",
      "            speed         pace      vo2Max         Age      Height  \\\n",
      "count  270.000000   270.000000  270.000000  270.000000  270.000000   \n",
      "mean     8.077148   522.151111   48.787630   40.374074  179.655556   \n",
      "std      2.333011   409.633998    5.289493   12.628112    7.338589   \n",
      "min      0.610000   299.380000   33.460000   26.000000  163.000000   \n",
      "25%      6.147500   361.497500   45.742500   27.000000  179.000000   \n",
      "50%      8.625000   417.480000   48.560000   42.000000  180.000000   \n",
      "75%      9.957500   585.730000   52.200000   54.000000  183.000000   \n",
      "max     12.020000  5860.810000   64.980000   60.000000  195.000000   \n",
      "\n",
      "           weight       sleep  sleep_quality  \n",
      "count  270.000000  270.000000     270.000000  \n",
      "mean    80.077778    6.943889      94.829630  \n",
      "std     11.755781    1.633208       2.726821  \n",
      "min     58.000000    0.980000      87.000000  \n",
      "25%     72.000000    6.257500      93.000000  \n",
      "50%     80.000000    7.065000      95.000000  \n",
      "75%     86.000000    7.895000      97.000000  \n",
      "max    100.000000   12.100000     100.000000  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "main_folder_path = \"./pmdata\"\n",
    "# Initialize an empty dictionary to store data for each column\n",
    "exercise = []\n",
    "# Iterate through the 16 main folders\n",
    "for folder_name in os.listdir(main_folder_path):\n",
    "    folder_path = os.path.join(main_folder_path, folder_name, 'fitbit')\n",
    "\n",
    "\n",
    "    # Check if the subfolder exists\n",
    "    if os.path.exists(folder_path):\n",
    "        file_path = os.path.join(folder_path, 'exercise.json')\n",
    "        \n",
    "        # Check if the \"exercise.json\" file exists in the subfolder\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as json_file:\n",
    "                # Load JSON data from the file\n",
    "                json_data = json.load(json_file)\n",
    "                # Add the data to the dictionary with the folder number as the key\n",
    "                df = pd.DataFrame(json_data)\n",
    "                df['user_id']= folder_name\n",
    "                exercise.append(df)\n",
    "\n",
    "exercise_data = pd.concat(exercise, ignore_index=True).sort_values(by=['user_id']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#Exploring the columns from the dataset.\n",
    "exercise_data = exercise_data.query(\"activityName == 'Run'\").dropna(subset=['distanceUnit'])\n",
    "exercise_data = exercise_data.drop(columns=['poolLengthUnit', 'hasGps', 'poolLength', 'swimLengths', 'logId', 'activityTypeId', 'logType', 'lastModified', 'tcxLink','distanceUnit', 'customHeartRateZones', 'shouldFetchDetails', 'manualValuesSpecified', 'source', 'activityLevel', 'heartRateZones', 'elevationGain', 'originalDuration', 'activeDuration', 'originalStartTime', 'activityName'])\n",
    "exercise_data = exercise_data[exercise_data[\"distance\"] > 0.5].reset_index(drop=True)\n",
    "exercise_data[\"vo2Max\"] = exercise_data[\"vo2Max\"].apply(lambda x: round(x.get(\"vo2Max\"), 2) if isinstance(x, dict) else None)\n",
    "exercise_data.loc[exercise_data['vo2Max'].isna(), 'vo2Max'] = pd.Series(\n",
    "    np.random.choice(\n",
    "        exercise_data['vo2Max'].dropna(),  # Sample from non-NaN values\n",
    "        size=exercise_data['vo2Max'].isna().sum(), \n",
    "        replace=True\n",
    "    ),\n",
    "    index=exercise_data[exercise_data['vo2Max'].isna()].index  # Maintain correct indices\n",
    ")\n",
    "exercise_data['startTime'] = pd.to_datetime(exercise_data['startTime'])\n",
    "exercise_data['duration'] = round(exercise_data['duration'] / 60000, 2)\n",
    "exercise_data['distance'] = round(exercise_data['distance'], 2)\n",
    "exercise_data['speed'] = round(exercise_data['speed'], 2)\n",
    "exercise_data['pace'] = round(exercise_data['pace'], 2)\n",
    "exercise_data['date'] = pd.to_datetime(exercise_data['startTime']).dt.date\n",
    "exercise_data = exercise_data.drop(columns=['startTime'])\n",
    "exercise_data.rename(columns={'averageHeartRate': 'avgHR'}, inplace=True)\n",
    "exercise_data = exercise_data.drop_duplicates(subset=['user_id', 'date'], keep='first')\n",
    "\n",
    "\n",
    "merged_df = exercise_data.merge(user_data, on='user_id', how='left')\n",
    "merged_df = merged_df.merge(x, on=['user_id', 'date'], how='left')\n",
    "merged_df = merged_df.drop_duplicates(keep='last')\n",
    "merged_df = merged_df.merge(sleep, on=['user_id', 'date'], how='left')\n",
    "\n",
    "\n",
    "# Fill missing 'alcohol_consumed' values with 'No'\n",
    "merged_df['alcohol_consumed'] = merged_df['alcohol_consumed'].fillna(\"No\")\n",
    "\n",
    "# Fill missing 'weight' values with the mean weight per user_id\n",
    "merged_df['weight'] = merged_df.groupby('user_id')['weight'].transform(lambda grp: round(grp.mean(skipna=True)) if grp.notna().any() else 80)\n",
    "merged_df['sleep'] = merged_df['sleep'].fillna(merged_df.groupby('user_id')['sleep'].transform(lambda grp: round(grp.mean(skipna=True)) if grp.notna().any() else 7))\n",
    "merged_df['sleep_quality'] = merged_df['sleep_quality'].fillna(merged_df.groupby('user_id')['sleep_quality'].transform(lambda grp: round(grp.mean(skipna=True)) if grp.notna().any() else 95))\n",
    "\n",
    "merged_df.dropna()\n",
    "\n",
    "\n",
    "print(merged_df.info())\n",
    "print(merged_df.describe())\n",
    "merged_df.to_csv(\"FinalDataset.csv\", index=False)\n",
    "# merged_df.query(\"sleep_quality == 0\")\n",
    "\n",
    "\n",
    "# merged_df.head(10)\n",
    "# print(merged_df)\n",
    "\n",
    "# merged_df.describe()\n",
    "# exercise_data.head(10)\n",
    "# exercise_data.value_counts('avgHR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
